{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Prisoner's Dilemma\n",
    "\n",
    "\n",
    "### Description\n",
    "\n",
    "The [Prisoner's Dilemma](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma) (PD) is a classical game analyzed in game theory, which is widely used to (attempt to) model social/economical interaction. It's a \"dilemma\" as, if exploited to explain the emergence of altruism in human or in general animal society, it fails badly at a first glance.\n",
    "\n",
    "The classical situation-representation of the PD is that of two prisoners whose conviction depends on their mutual cooperation. It is easier understood though if illustrated in terms of a trade-off game (closed bag exachange):\n",
    "\n",
    "*Two people meet and exchange closed bags, with the understanding that one of them contains money, and the other contains a purchase. Either player can choose to honor the deal by putting into his or her bag what he or she agreed, or he or she can defect by handing over an empty bag.*\n",
    "\n",
    "It is obvious that for both players the winning strategy is to NOT cooperate.\n",
    "\n",
    "Things changes when the interaction between the two individuals is iterated, in that case a more altruist attitude (strategy) is expected to emerge. The goal of this project is to test this hypothesis.\n",
    "\n",
    "Mathematically the PD can be expressed with very basic linear algebra. The key component is the **Payoff matrix** $M$, which quantify the reward each player gets depending on whether she cooperated or not (defect):\n",
    "\n",
    "$$\n",
    "M = \n",
    "\\begin{pmatrix} \n",
    "R & S \\\\\n",
    "T & P \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "with $T,R,S,P$ integers that satisfy the following conditions:\n",
    "\n",
    "$$\n",
    "T>R>P>S; \\quad 2R > T+S\n",
    "$$\n",
    "\n",
    "for example $T=3$, $R=2$, $P=1$ and $S=0$, or  $T=5$, $R=3$, $P=2$, $S=0$. Each player choice (move) can be represented by one of the two axis in ${\\rm I\\!R}^2$, i.e. $u_C=\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ or $u_D=\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, where the first coordinate stands for *Cooperate* and the second for *Defect*. Being $u_1$ and $u_2$ their rewards $r_1$ and $r_2$ can be computed then as:\n",
    "\n",
    "$$\n",
    "r_1 = u_1^T M u_2\n",
    "\\quad\n",
    "\\quad\n",
    "r_2 = u_2^T M u_1\n",
    "$$\n",
    "\n",
    "In an Iterative Prisoner's Dilemma (IPD), two players play prisoner's dilemma more than once in succession and they remember previous actions of their opponent and change their strategy accordingly. The winning strategy is the one which yields to a larger reward at the end of the IPD.\n",
    "\n",
    "The strategy can be represented as a function which outputs either $u_C$ or $u_D$. Such function can depend on the opponent's history of moves, her on history of moves, on the number of moves played till that moment and so on, but it can only be based on a probability density function. Possible strategies are:\n",
    "\n",
    "* **Nice guy**: always cooperate (the function's output is always $u_D$)\n",
    "* **Bad guy**: always defect \n",
    "* **Mainly nice**: randomly defect $k\\%$ of the times and cooperate $100-k\\%$, $k<50$\n",
    "* **Mainly bad**: randomly defect $k\\%$ of the times and cooperate $100-k\\%$, $k>50$\n",
    "* **tit-for-tat**: start by cooperating, then repeat what the opponent has done in the previous move \n",
    "\n",
    "Many more and much more complex strategies can be implemented. The strategy can even change during the IPD.\n",
    "\n",
    "\n",
    "### Assignments\n",
    "\n",
    "* Implement a simple IPD between two players implementing two given strategies. Study the evolution along the tournament confronting different strategies; study the overall outcome in the different configurations. \n",
    "* Implement a multiple players IPD (MPIPD) where several strategies play against each other in a roud-robin scheme\n",
    "* Iterate what done in the previous task (repeated MPIPD, rMPIPD)  by increasing the population implementing a given strategy depending on the results that strategy achieved in the previous iteration\n",
    "* (*difficult*) Implement a rMPIPD where strategies are allowed to mutate. The goal is to simulate the effect of genetic mutations and the effect of natura selection. A parameter (gene) should encode the attidue of an individual to cooperate, such gene can mutate randomly and the corresponding phenotype should compete in the MPIPD such that the best-fitted is determined.  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic elements and 1-on-1 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a `Player` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "    \n",
    "    def play(self, hist):\n",
    "        return random() < self.k\n",
    " \n",
    "# special child class for tit-for-tat strategies (see later)\n",
    "class TftPlayer(Player):\n",
    "    def play(self, hist):\n",
    "        return hist[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a function that implements the basic 1-on-1 game mechanics. The default payoff matrix will be\n",
    "$$\n",
    "    M = \\begin{pmatrix} 2 & 0 \\\\ 3 & 1 \\end{pmatrix},\n",
    "$$\n",
    "corresponding to\n",
    "$$\n",
    "    R = 2,\\, S = 0,\\, T = 3,\\, P = 1.\n",
    "$$\n",
    "If both players cooperate, they both receive 2 points (**R**eward). If they betray each other, they each receive 1 point (**P**unishment). If one player betrays their cooperative opponent, the betrayer receives 3 points (**T**emptation payoff) while the betrayed player gets 0 (**S**ucker’s payoff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game(pl1, pl2, it, payoff=(3, 2, 1, 0)):\n",
    "    hist1 = [True] # only for the correct initialization of tit-for-tat\n",
    "    hist2 = [True] # same\n",
    "    points = [0, 0]\n",
    "    \n",
    "    for i in range(it):\n",
    "        res1 = pl1.play(hist2)\n",
    "        res2 = pl2.play(hist1)\n",
    "        hist1.append(res1)\n",
    "        hist2.append(res2)\n",
    "        if res1 and res2:\n",
    "            points[0] += payoff[1]\n",
    "            points[1] += payoff[1]\n",
    "        elif res1 and not res2:\n",
    "            points[1] += payoff[0]\n",
    "            points[0] += payoff[3]\n",
    "        elif not res1 and res2:\n",
    "            points[1] += payoff[3]\n",
    "            points[0] += payoff[0]\n",
    "        else:\n",
    "            points[0] += payoff[2]\n",
    "            points[1] += payoff[2]\n",
    " \n",
    "    return points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the following basic strategies:\n",
    "* _nice player_, a player who always cooperates;\n",
    "* _evil player_, a player who always betrays.\n",
    "\n",
    "And the intermediate versions:\n",
    "* _average player_, a player who cooperates half the time;\n",
    "* _mostly nice player_, a player with a cooperation probability of 0.75;\n",
    "* _mostly bad player_, a player with a cooperation probability of 0.25.\n",
    "\n",
    "Also, we’ll implement a basic example of a different kind of strategy, commonly referred to as “tit-for-tat”. A tit-for-tat player starts by cooperating on the first iteration and then copies their opponent’s previous move from that point forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_pl = Player(1)\n",
    "evil_pl = Player(0)\n",
    "avg_pl = Player(0.5)\n",
    "mnice_pl = Player(0.75)\n",
    "mevil_pl = Player(0.25)\n",
    "tt_pl = TftPlayer(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s examine some 1-on-1 matchups of these strategies.\n",
    "\n",
    "The result of a nice versus evil match is easily predicted: Nice will always receive the sucker’s payoff, while Evil will receive a temptation reward in every iteration, resulting in a score of T times the number of iterations to zero in favour of the betrayer.\n",
    "\n",
    "If the number of iterations is large enough, matchups between mostly nice/evil players are also predictable. For example, in the Evil versus Average matchup, the score ratio will converge to 4 in favour of Evil.\n",
    "This is because half the time both players will receive $P = 1$ points (reciprocal betrayal), while in the other instances Evil will receive $T=3$ points and Average will receive $S = 0$. So, if $E$ is Evil’s score and $A$ is Average’s,\n",
    "$$\n",
    "    \\frac{E}{A} \\approx \\frac{P / 2 + T / 2}{P / 2 + S / 2} = 4.\n",
    "$$\n",
    "Indeed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evil v Average:\n",
      " [2014, 493]\n",
      "Score ratio: 2014 / 493 = 4.085192697768763\n"
     ]
    }
   ],
   "source": [
    "iters = 1000\n",
    "evil_v_avg = game(evil_pl, avg_pl, iters)\n",
    "print(f\"Evil v Average:\\n {evil_v_avg}\")\n",
    "print(f\"Score ratio: {evil_v_avg[0]} / {evil_v_avg[1]} \\\n",
    "= {evil_v_avg[0] / evil_v_avg[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrayal usually prevails, as seen in the classic dilemma. The situation becomes more intriguing when a tit-for-tat player is introduced. Let's observe how they fare with the reigning champion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tit-for-tat v Evil:\n",
      " [999, 1002]\n"
     ]
    }
   ],
   "source": [
    "tt_v_evil = game(tt_pl, evil_pl, iters)\n",
    "print(f\"Tit-for-tat v Evil:\\n {tt_v_evil}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evil wins by three points. The first move is crucial: Tit-for-tat cooperates initially and hence loses three points to Evil. From that point on, they engage in reciprocal betrayal in every turn, resulting in each player earning one point. With our 1000 iterations, the final score becomes 999 to 1002.\n",
    "\n",
    "Then, what happens to the other players? To get the full picture, we’ll play a small tournament among these six players and look at the averaged scores at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_robin(players, iters, num_games):\n",
    "    N = len(players)\n",
    "    results = np.zeros((N, N))\n",
    "    for g in range(num_games):\n",
    "        for i in range(N):\n",
    "            # start from i to allow players to compete against themselves\n",
    "            for j in range(i, N):\n",
    "                score = game(players[i], players[j], iters)\n",
    "                # results[i, j] is the sum of all points made\n",
    "                # by player i when playing j\n",
    "                results[i, j] += score[0]\n",
    "                if i == j:\n",
    "                    continue # avoid double counting\n",
    "                results[j, i] += score[1]\n",
    "\n",
    "    # return average points per iteration\n",
    "    return results / (num_games * iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [nice_pl, evil_pl, avg_pl, mnice_pl, mevil_pl, tt_pl]\n",
    "\n",
    "tournament = round_robin(players, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdbb663ad9ba1b792610492e9c14cc4502c8785e473cf31bd41558f2f35aac4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
